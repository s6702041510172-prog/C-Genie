import os
import re
import fitz  
import difflib
import streamlit as st
import google.generativeai as genai
import time
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from dotenv import load_dotenv

# -------------------------------
# CONFIG API
# -------------------------------
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY", "AIzaSyBlaAYDZu2yhYlaShDnZoMoCkBA0lSGoaE"))

generation_config = {
    "temperature": 0.35,
    "top_p": 0.9,
    "top_k": 64,
    "max_output_tokens": 1600,
    "response_mime_type": "text/plain"
}

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

PROMPT_SYSTEM = """
ROLE:
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ Chatbot ‡∏ä‡∏∑‡πà‡∏≠ ‚ÄúC-Genie‚Äù ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤ C
‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ï‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤ C
‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

OBJECTIVE:
- ‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤ C ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å (Active Learning)
- ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç ‡∏•‡∏π‡∏õ ‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡πå‡πÄ‡∏£‡∏¢‡πå
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£

CONSTRAINTS:
1. ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (PDF) ‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
3. ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ß‡πà‡∏≤ ‚Äú‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ñ‡πà‡∏∞‚Äù
4. ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤
5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏≠‡∏∏‡∏î‡∏°‡∏®‡∏∂‡∏Å‡∏©‡∏≤

INSTRUCTION FOR RESPONSE:
- ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠ ‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
- ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Markdown:
  ```c
  // ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î

"""

model = genai.GenerativeModel(
    model_name="models/gemini-2.5-flash",
    safety_settings=SAFETY_SETTINGS,
    generation_config=generation_config,
    system_instruction=PROMPT_SYSTEM,
)

# -------------------------------
# ‡∏≠‡πà‡∏≤‡∏ô PDF (‡∏î‡πâ‡∏ß‡∏¢ fitz)
# -------------------------------
@st.cache_data(show_spinner=False)
def load_pdf(file_path):
    text = ""
    with fitz.open(file_path) as pdf:
        for page in pdf:
            text += page.get_text("text") + "\n\n"
    return text.strip()

# -------------------------------
# ‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å PDF
# -------------------------------
def split_chunks(text, size=1200, overlap=200):
    chunks, start = [], 0
    while start < len(text):
        end = min(start + size, len(text))
        chunks.append(text[start:end])
        if end == len(text):
            break
        start = end - overlap
    return chunks


def search_chunks(query, chunks, top_k=8):
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ chunk ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    ‡∏û‡∏£‡πâ‡∏≠‡∏° boost ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô '‡∏†‡∏≤‡∏©‡∏≤ C', '‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô', '‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£', '‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á'
    """
    boost_keywords = ["‡∏†‡∏≤‡∏©‡∏≤ C", "‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô", "‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á", "‡∏û‡∏±‡∏í‡∏ô‡∏≤", "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏Ñ.‡∏®.", "Ritchie", "BCPL"]
    scored = []

    for c in chunks:
        score = difflib.SequenceMatcher(None, query.lower(), c.lower()).ratio()
        for kw in boost_keywords:
            if kw in c:
                score += 0.08  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏´‡∏≤‡∏Å‡πÄ‡∏à‡∏≠‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        scored.append((score, c))

    scored.sort(reverse=True)
    return [c for _, c in scored[:top_k]]

# -------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
# -------------------------------
def generate_response(prompt, file_content, user_prompt_addon, chat_key):
    chunks = split_chunks(file_content)
    related = search_chunks(prompt, chunks, top_k=8)
    context = "\n\n".join(related)

    # ‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏´‡πâ‡∏≠‡∏á
    history_text = ""
    for msg in st.session_state["chats"][chat_key]:
        role = "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ" if msg["role"] == "user" else "C-Genie"
        history_text += f"{role}: {msg['content']}\n"

    query = f"""
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:
{context}

‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:
{history_text}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:
{prompt}

‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:
{user_prompt_addon}
"""

    response = model.generate_content(query)
    return response.text.strip() if response and response.candidates and response.candidates[0].content.parts else "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ñ‡πà‡∏∞"

# -------------------------------
# UI
# -------------------------------
st.set_page_config(page_title="C-Genie", page_icon="üßû", layout="wide")
st.title("üßû C-Genie ‚Äî ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤ C")

# -------------------------------
# Sidebar: ‡∏´‡πâ‡∏≠‡∏á‡πÅ‡∏ä‡∏ó + prompt ‡πÄ‡∏û‡∏¥‡πà‡∏°
# -------------------------------
with st.sidebar:
    st.markdown("### üí¨ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏ó‡∏ô‡∏≤")

    if "chats" not in st.session_state:
        st.session_state["chats"] = {"‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô": []}
    if "active_chat" not in st.session_state:
        st.session_state["active_chat"] = "‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"

    chat_names = list(st.session_state["chats"].keys())
    chat_key = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡πâ‡∏≠‡∏á‡πÅ‡∏ä‡∏ó", chat_names, index=chat_names.index(st.session_state["active_chat"]))
    st.session_state["active_chat"] = chat_key

    new_chat = st.text_input("‚ûï ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡πâ‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà", placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô, ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£, Loop ...")
    if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡πâ‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà"):
        if new_chat.strip():
            if new_chat not in st.session_state["chats"]:
                st.session_state["chats"][new_chat] = []
                st.session_state["active_chat"] = new_chat
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
        else:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏´‡πâ‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô")

    if st.button("üóëÔ∏è ‡∏•‡∏ö‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏µ‡πâ"):
        if chat_key != "‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô":
            del st.session_state["chats"][chat_key]
            st.session_state["active_chat"] = "‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"
            st.rerun()
        else:
            st.warning("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÑ‡∏î‡πâ")

    st.markdown("---")
    user_prompt_addon = st.text_area("üí° ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏≠‡∏ó (‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ô‡∏ß‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö)", height=80)

    if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏µ‡πâ"):
        st.session_state["chats"][chat_key] = []
        st.rerun()

# -------------------------------
# ‡πÇ‡∏´‡∏•‡∏î PDF
# -------------------------------
file_path = "datasetC.pdf"
if not os.path.exists(file_path):
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå datasetC.pdf")
    st.stop()

file_content = load_pdf(file_path)

# -------------------------------
# ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
# -------------------------------
if len(st.session_state["chats"][chat_key]) == 0:
    st.markdown("""
    ### üëã ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà **C-Genie ‚Äì ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤ C**
    ‡∏â‡∏±‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ö‡∏ó ‡πÄ‡∏ä‡πà‡∏ô:
    1Ô∏è‚É£ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏†‡∏≤‡∏©‡∏≤ C  
    2Ô∏è‚É£ ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÅ‡∏•‡∏∞‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•  
    3Ô∏è‚É£ ‡∏ï‡∏±‡∏ß‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡∏û‡∏à‡∏ô‡πå  
    4Ô∏è‚É£ ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°  
    5Ô∏è‚É£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡πå‡πÄ‡∏£‡∏¢‡πå  
    """)

# -------------------------------
# ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏ô‡∏´‡πâ‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
# -------------------------------
st.subheader(f"üí¨ ‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏ó‡∏ô‡∏≤: {chat_key}")
for msg in st.session_state["chats"][chat_key]:
    st.chat_message(msg["role"]).write(msg["content"])

# -------------------------------
# ‡∏ä‡πà‡∏≠‡∏á‡πÅ‡∏ä‡∏ó‡∏´‡∏•‡∏±‡∏Å
# -------------------------------
if prompt := st.chat_input(f"‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô {chat_key} ..."):
    st.chat_message("user").write(prompt)
    st.session_state["chats"][chat_key].append({"role": "user", "content": prompt})

    with st.chat_message("model"):
        with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£..."):
            reply = generate_response(prompt, file_content, user_prompt_addon, chat_key)
            message_placeholder = st.empty()
            displayed = ""
            for char in reply:
                displayed += char
                message_placeholder.markdown(displayed)
                time.sleep(0.004)

    st.session_state["chats"][chat_key].append({"role": "model", "content": reply})
